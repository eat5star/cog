Exp 5 Classification of text using supervised learing

import nltk
nltk.download('movie_reviews')
from nltk.corpus import movie_reviews
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import random
# Prepare the raw text data
documents = []
for category in movie_reviews.categories():
    for fileid in movie_reviews.fileids(category):
        documents.append((movie_reviews.raw(fileid), category))
# Shuffle the documents
random.shuffle(documents)
# Split features and labels
texts = [doc for doc, _ in documents]
labels = [category for _, category in documents]
# Split into training and testing sets (80-20 split)
train_size = int(len(texts) * 0.8)
train_texts = texts[:train_size]
train_labels = labels[:train_size]
test_texts = texts[train_size:]
test_labels = labels[train_size:]

# Create TF-IDF vectorizer
vectorizer = TfidfVectorizer(max_features=5000,
                            stop_words='english',
                            ngram_range=(1,2))
# Transform text to TF-IDF features
X_train = vectorizer.fit_transform(train_texts)
X_test = vectorizer.transform(test_texts)
# Dictionary to store Result
Result = {}
# 1. Naive Bayes Classifier
nb_classifier = MultinomialNB()
nb_classifier.fit(X_train, train_labels)
nb_pred = nb_classifier.predict(X_test)
Result['Naive Bayes'] = accuracy_score(test_labels, nb_pred)
# 2. Support Vector Machine
svm_classifier = LinearSVC(random_state=42)
svm_classifier.fit(X_train, train_labels)
svm_pred = svm_classifier.predict(X_test)
Result['SVM'] = accuracy_score(test_labels, svm_pred)
# 3. Logistic Regression
lr_classifier = LogisticRegression(random_state=42, max_iter=1000)
lr_classifier.fit(X_train, train_labels)
lr_pred = lr_classifier.predict(X_test)
Result['Logistic Regression'] = accuracy_score(test_labels, lr_pred)
# 4. Random Forest
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, train_labels)
rf_pred = rf_classifier.predict(X_test)
Result['Random Forest'] = accuracy_score(test_labels, rf_pred)
# Print Result
print("Classification Result:")
print("-" * 50)
for model, accuracy in Result.items():
    print(f"{model}: {accuracy:.4f}")
# Detailed classification report for the best performing model
best_model = max(Result, key=Result.get)
print(f"\nDetailed Report for Best Model ({best_model}):")
if best_model == 'Naive Bayes':
    best_pred = nb_pred
elif best_model == 'SVM':
    best_pred = svm_pred
elif best_model == 'Logistic Regression':
    best_pred = lr_pred
else:
    best_pred = rf_pred

print(classification_report(test_labels, best_pred))
# Example prediction
sample_text = "This movie was absolutely fantastic and thrilling!"
sample_vector = vectorizer.transform([sample_text])
sample_pred = svm_classifier.predict(sample_vector)
print(f"\nSample prediction: {sample_text}")
print(f"Predicted sentiment: {sample_pred[0]}")
